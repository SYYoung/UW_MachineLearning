{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: LASSO (coordinate descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement your very own LASSO solver via coordinate descent. You will:\n",
    "* Write a function to normalize features\n",
    "* Implement coordinate descent for LASSO\n",
    "* Explore effects of L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of graphlab (>= 1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to r38411@yahoo.com and will expire on August 31, 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1542532215.log\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to int, before using it below\n",
    "sales['floors'] = sales['floors'].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any \"feature engineering\" like creating new features or adjusting existing ones we should do this directly using the SFrames as seen in the first notebook of Week 2. For this notebook, however, we will work with the existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we convert the SFrame into a 2D Numpy array. Copy and paste `get_num_data()` from the second notebook of Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe.select_columns(features)\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, copy and paste the `predict_output()` function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize features\n",
    "In the house dataset, features vary wildly in their relative magnitude: `sqft_living` is very large overall compared to `bedrooms`, for instance. As a result, weight for `sqft_living` would be much smaller than weight for `bedrooms`. This is problematic because \"small\" weights are dropped first as `l1_penalty` goes up. \n",
    "\n",
    "To give equal considerations for all features, we need to **normalize features** as discussed in the lectures: we divide each feature by its 2-norm so that the transformed feature has norm 1.\n",
    "\n",
    "Let's see how we can do this normalization easily with Numpy: let us first consider a small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   5.   8.]\n",
      " [  4.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3.,5.,8.],[4.,12.,15.]])\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy provides a shorthand for computing 2-norms of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.  13.  17.]\n"
     ]
    }
   ],
   "source": [
    "norms = np.linalg.norm(X, axis=0) # gives [norm(X[:,0]), norm(X[:,1]), norm(X[:,2])]\n",
    "print norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize, apply element-wise division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6         0.38461538  0.47058824]\n",
      " [ 0.8         0.92307692  0.88235294]]\n"
     ]
    }
   ],
   "source": [
    "print X / norms # gives [X[:,0]/norm(X[:,0]), X[:,1]/norm(X[:,1]), X[:,2]/norm(X[:,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the shorthand we just covered, write a short function called `normalize_features(feature_matrix)`, which normalizes columns of a given feature matrix. The function should return a pair `(normalized_features, norms)`, where the second item contains the norms of original features. As discussed in the lectures, we will use these norms to normalize the test data in the same way as we normalized the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    norm_feature = feature_matrix/norms\n",
    "    return (norm_feature, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6  0.6  0.6]\n",
      " [ 0.8  0.8  0.8]]\n",
      "[  5.  10.  15.]\n"
     ]
    }
   ],
   "source": [
    "features, norms = normalize_features(np.array([[3.,6.,9.],[4.,8.,12.]]))\n",
    "print features\n",
    "# should print\n",
    "# [[ 0.6  0.6  0.6]\n",
    "#  [ 0.8  0.8  0.8]]\n",
    "print norms\n",
    "# should print\n",
    "# [5.  10.  15.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Coordinate Descent with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seek to obtain a sparse set of weights by minimizing the LASSO cost function\n",
    "```\n",
    "SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|).\n",
    "```\n",
    "(By convention, we do not include `w[0]` in the L1 penalty term. We never want to push the intercept to zero.)\n",
    "\n",
    "The absolute value sign makes the cost function non-differentiable, so simple gradient descent is not viable (you would need to implement a method called subgradient descent). Instead, we will use **coordinate descent**: at each iteration, we will fix all weights but weight `i` and find the value of weight `i` that minimizes the objective. That is, we look for\n",
    "```\n",
    "argmin_{w[i]} [ SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|) ]\n",
    "```\n",
    "where all weights other than `w[i]` are held to be constant. We will optimize one `w[i]` at a time, circling through the weights multiple times.  \n",
    "  1. Pick a coordinate `i`\n",
    "  2. Compute `w[i]` that minimizes the cost function `SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|)`\n",
    "  3. Repeat Steps 1 and 2 for all coordinates, multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we use **cyclical coordinate descent with normalized features**, where we cycle through coordinates 0 to (d-1) in order, and assume the features were normalized as discussed above. The formula for optimizing each coordinate is as follows:\n",
    "```\n",
    "       ┌ (ro[i] + lambda/2)     if ro[i] < -lambda/2\n",
    "w[i] = ├ 0                      if -lambda/2 <= ro[i] <= lambda/2\n",
    "       └ (ro[i] - lambda/2)     if ro[i] > lambda/2\n",
    "```\n",
    "where\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ].\n",
    "```\n",
    "\n",
    "Note that we do not regularize the weight of the constant feature (intercept) `w[0]`, so, for this weight, the update is simply:\n",
    "```\n",
    "w[0] = ro[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple model with 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to normalize features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_feature_matrix, norms = normalize_features(simple_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign some random set of initial weights and inspect the values of `ro[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.array([1., 4., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_output()` to make predictions on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = predict_output(simple_feature_matrix, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the values of `ro[i]` for each feature in this simple model, using the formula given above, using the formula:\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n",
    "```\n",
    "\n",
    "*Hint: You can get a Numpy vector for feature_i using:*\n",
    "```\n",
    "simple_feature_matrix[:,i]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.794e+07 8.097e+07\n"
     ]
    }
   ],
   "source": [
    "def get_ro(which_index, feature_matrix, weights, output, prediction):\n",
    "    pred_error = output - prediction + weights[which_index]*feature_matrix[:,which_index]\n",
    "    rho = np.dot(feature_matrix[:,which_index], pred_error).sum()\n",
    "\n",
    "rho_test = [1, 4, 1]\n",
    "for i in range(1,3):\n",
    "    pred_error = output - prediction + weights[i]*simple_feature_matrix[:,i]\n",
    "    rho_test[i] = np.dot(simple_feature_matrix[:,i], pred_error).sum()\n",
    "print \"%.4g\" %rho_test[1], \"%.4g\" %rho_test[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Recall that, whenever `ro[i]` falls between `-l1_penalty/2` and `l1_penalty/2`, the corresponding weight `w[i]` is sent to zero. Now suppose we were to take one step of coordinate descent on either feature 1 or feature 2. What range of values of `l1_penalty` **would not** set `w[1]` zero, but **would** set `w[2]` to zero, if we were to take a step in that coordinate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62e+08 1.76e+08\n"
     ]
    }
   ],
   "source": [
    "# in order for w_i to be set to 0, lambda > 2*ro_i\n",
    "# in order for w_i to be non-zero, lambda < 2*ro_i\n",
    "# if w_1 != 0 , w_2=0, lambda < 2*r1 and lambda > 2*r2, i.e. lambda = (2*r2, 2*r1)\n",
    "lambda_min = 2*rho_test[2]\n",
    "lambda_max = 2*rho_test[1] -1\n",
    "print \"%.3g\" %lambda_min, \"%.3g\" %lambda_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What range of values of `l1_penalty` would set **both** `w[1]` and `w[2]` to zero, if we were to take a step in that coordinate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76e+08\n"
     ]
    }
   ],
   "source": [
    "# in order for w1 and w2 to be set to 0, lambda > 2*r1 and lambda > 2*r2\n",
    "lambda_max = 2*max(rho_test[1], rho_test[2])\n",
    "print '%.3g' %lambda_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can say that `ro[i]` quantifies the significance of the i-th feature: the larger `ro[i]` is, the more likely it is for the i-th feature to be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formula above, implement coordinate descent that minimizes the cost function over a single feature i. Note that the intercept (weight 0) is not regularized. The function should accept feature matrix, output, current weights, l1 penalty, and index of feature to optimize over. The function should return new weight for feature i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix, weights)\n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    pred_error = output - prediction + weights[i]*feature_matrix[:,i]\n",
    "    ro_i = np.dot(feature_matrix[:,i], pred_error).sum()\n",
    "\n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = ro_i \n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i + l1_penalty/2\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i - l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425558846691\n"
     ]
    }
   ],
   "source": [
    "# should print 0.425558846691\n",
    "import math\n",
    "print lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],[2./math.sqrt(13),3./math.sqrt(10)]]), \n",
    "                                   np.array([1., 1.]), np.array([1., 4.]), 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that optimizes the cost function over a single coordinate, let us implement cyclical coordinate descent where we optimize coordinates 0, 1, ..., (d-1) in order and repeat.\n",
    "\n",
    "When do we know to stop? Each time we scan all the coordinates (features) once, we measure the change in weight for each coordinate. If no coordinate changes by more than a specified threshold, we stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each iteration:\n",
    "1. As you loop over features in order and perform coordinate descent, measure how much each coordinate changes.\n",
    "2. After the loop, if the maximum change across all coordinates is falls below the tolerance, stop. Otherwise, go back to step 1.\n",
    "\n",
    "Return weights\n",
    "\n",
    "**IMPORTANT: when computing a new weight for coordinate i, make sure to incorporate the new weights for coordinates 0, 1, ..., i-1. One good way is to update your weights variable in-place. See following pseudocode for illustration.**\n",
    "```\n",
    "for i in range(len(weights)):\n",
    "    old_weights_i = weights[i] # remember old value of weight[i], as it will be overwritten\n",
    "    # the following line uses new values for weight[0], weight[1], ..., weight[i-1]\n",
    "    #     and old values for weight[i], ..., weight[d-1]\n",
    "    weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "    \n",
    "    # use old_weights_i to compute change in coordinate\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    max_change = 1000 * tolerance\n",
    "    weights = np.copy(initial_weights)\n",
    "    print 'before while loop, max_change = ', max_change\n",
    "    print weights\n",
    "    while (max_change > tolerance):\n",
    "        max_change = tolerance\n",
    "        for i in range(len(weights)):\n",
    "            old_weights_i = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            change_weight = abs(old_weights_i - weights[i])\n",
    "            max_change = max(max_change, change_weight)\n",
    "        print weights\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following parameters, learn the weights on the sales dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a normalized version of the feature matrix, `normalized_simple_feature_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)\n",
    "(normalized_simple_feature_matrix, simple_norms) = normalize_features(simple_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run your implementation of LASSO coordinate descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(normalized_simple_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63e+15\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(normalized_simple_feature_matrix, weights)\n",
    "pred_error = output - prediction\n",
    "rss = (pred_error ** 2).sum()\n",
    "print \"%.4g\" %rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz questions:\n",
    "## rss of normalized_simple_feature_matrix, rss = 1.63e+15.\n",
    "## the feature: bedroom has been set to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What is the RSS of the learned model on the normalized dataset? (Hint: use the normalized feature matrix when you make predictions.)\n",
    "2. Which features had weight zero at convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LASSO fit with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the sales dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a normalized feature matrix from the TRAINING data with these features.  (Make you store the norms for the normalization, since we'll use them later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(all_train_feature_matrix, all_output) = get_numpy_data(train_data, all_features, my_output)\n",
    "(normalized_all_train_feature_matrix, all_train_norms) = normalize_features(all_train_feature_matrix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, learn the weights with `l1_penalty=1e7`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e7`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(len(all_features)+1)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, learn the weights with `l1_penalty=1e8`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e8`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before while loop, max_change =  1000.0\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 71114625.75280938         0.           3743972.43191673\n",
      "   5271064.34696085         0.                 0.           7173100.28480826\n",
      "   7025132.06642577  -5530804.65691784         0.            394565.5843951\n",
      "   2242690.39485069  -2160960.47385677         0.        ]\n",
      "[ 66090269.38411944         0.           5640929.90486558\n",
      "   9576074.08584593         0.                 0.           4372018.67087034\n",
      "   8681306.06747757  -5916544.37101573         0.                 0.\n",
      "   2344289.56079889  -2427081.50004132         0.        ]\n",
      "[ 61077944.47016688         0.           6858126.86985249\n",
      "  13615612.28257743         0.                 0.           3592460.38136717\n",
      "   8827496.44124511  -5139390.82173171         0.                 0.\n",
      "   1473793.21583144  -2523078.87389485         0.        ]\n",
      "[ 56077268.04930486         0.           7597643.55215972\n",
      "  17477273.39390057         0.                 0.           3454915.18215362\n",
      "   8778283.91626904  -3739993.93385284         0.                 0.\n",
      "    553532.20275255  -2599789.5856098          0.        ]\n",
      "[ 51086024.87616502         0.           7940108.9597906   21166079.78641377\n",
      "         0.                 0.           3408675.87286224\n",
      "   8715945.98821977  -1827206.47373672         0.                 0.\n",
      "         0.          -2862294.95309065         0.        ]\n",
      "[ 46101663.532811           0.           7923070.30619179\n",
      "  24660952.87878784         0.                 0.           3357014.5067389\n",
      "   8609964.29727856         0.                 0.                 0.\n",
      "         0.          -2821325.28954632         0.        ]\n",
      "[ 41122158.60360589         0.           7564250.37938541\n",
      "  27935328.02331408         0.                 0.           3303237.80483547\n",
      "   8426877.62878147         0.                 0.                 0.\n",
      "    164424.74329385   -535700.94289839         0.        ]\n",
      "[ 36148352.03835092         0.           6897153.9464543   31000225.66654859\n",
      "         0.                 0.           3287534.55462106\n",
      "   8231044.69741986         0.                 0.                 0.\n",
      "    122579.09367796         0.                 0.        ]\n",
      "[ 33519131.51280316         0.           6001531.02429422\n",
      "  33879448.66593295         0.                 0.           3295337.93820763\n",
      "   8074870.24225422         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 31840636.33389109         0.           4928867.266338    36585599.43215322\n",
      "         0.                 0.           3299752.5882407    7953234.05021375\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 30409496.85243232         0.           3705897.13084735\n",
      "  39117895.08079505         0.                 0.           3291468.13866393\n",
      "   7833459.27138488         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 29279072.8300789          0.           2368683.30339511\n",
      "  41486211.65861711         0.                 0.           3288420.79846091\n",
      "   7723380.69771029         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 28402586.06414697         0.            947126.04373106\n",
      "  43699336.00928315         0.                 0.           3287240.84588382\n",
      "   7624767.90587166         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 27743688.99918688         0.                 0.          45251779.60941455\n",
      "         0.                 0.           3293773.58945422\n",
      "   7548697.23422141         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 27235850.96602788         0.                 0.          45743955.32843313\n",
      "         0.                 0.           3308697.42773068\n",
      "   7506238.67345057         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 26797036.59543666         0.                 0.          46159317.16186339\n",
      "         0.                 0.           3313254.30640554\n",
      "   7476716.65571677         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 26425556.97282853         0.                 0.          46509519.18337359\n",
      "         0.                 0.           3314649.10154074\n",
      "   7453273.45223347         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 26112141.86724785         0.                 0.          46804732.86823682\n",
      "         0.                 0.           3315254.98875543\n",
      "   7433823.25768144         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 25847897.03510908         0.                 0.          47053583.39546044\n",
      "         0.                 0.           3315642.31717273\n",
      "   7417493.51913731         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 25625143.17430942         0.                 0.          47263350.30884484\n",
      "         0.                 0.           3315942.73826208\n",
      "   7403742.24942826         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 25437372.50700296         0.                 0.          47440171.58817237\n",
      "         0.                 0.           3316190.514538     7392153.60601597\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 25279092.41364577         0.                 0.          47589221.54446636\n",
      "         0.                 0.           3316398.23528126   7382385.6595507\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 25145671.51203963         0.                 0.          47714861.89066111\n",
      "         0.                 0.           3316573.09391967   7374151.9801655\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 25033205.52374352         0.                 0.          47820769.30926737\n",
      "         0.                 0.           3316720.43991409\n",
      "   7367211.49898669         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24938403.31029161         0.                 0.          47910043.03042248\n",
      "         0.                 0.           3316844.63359071\n",
      "   7361361.08723077         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24858490.62284108         0.                 0.          47985295.52339269\n",
      "         0.                 0.           3316949.31939949\n",
      "   7356429.53556118         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24791128.93022151         0.                 0.          48048728.94615556\n",
      "         0.                 0.           3317037.56292694\n",
      "   7352272.52797431         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24734346.98772946         0.                 0.          48102199.58831158\n",
      "         0.                 0.           3317111.94693379\n",
      "   7348768.41527911         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24686483.15197742         0.                 0.          48147272.19275206\n",
      "         0.                 0.           3317174.64825439\n",
      "   7345814.65451413         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24646136.75535793         0.                 0.          48185265.74564613\n",
      "         0.                 0.           3317227.50177345\n",
      "   7343324.80802849         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24612127.11750609         0.                 0.          48217292.07470857\n",
      "         0.                 0.           3317272.0541786    7341226.01397599\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24583458.9943596          0.                 0.          48244288.38526879\n",
      "         0.                 0.           3317309.60923393\n",
      "   7339456.85410976         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24559293.45374667         0.                 0.          48267044.68626238\n",
      "         0.                 0.           3317341.26593531\n",
      "   7337965.55646256         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24538923.32521988         0.                 0.          48286226.90872776\n",
      "         0.                 0.           3317367.95067149\n",
      "   7336708.48031304         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24521752.50571107         0.                 0.          48302396.39333841\n",
      "         0.                 0.           3317390.44433361\n",
      "   7335648.83910145         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24507278.51541609         0.                 0.          48316026.31724562\n",
      "         0.                 0.           3317409.40516696\n",
      "   7334755.62392295         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24495077.79343238         0.                 0.          48327515.54094011\n",
      "         0.                 0.           3317425.38803358\n",
      "   7334002.69609568         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24484793.30284686         0.                 0.          48337200.28034148\n",
      "         0.                 0.           3317438.8606495    7333368.02224923\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24476124.08255444         0.                 0.          48345363.94568271\n",
      "         0.                 0.           3317450.21727182   7332833.029549\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24468816.44005588         0.                 0.          48352245.43511075\n",
      "         0.                 0.           3317459.79023607\n",
      "   7332382.06218852         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24462656.52750488         0.                 0.          48358046.12570361\n",
      "         0.                 0.           3317467.85968154\n",
      "   7332001.92324434         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24457464.08375253         0.                 0.          48362935.76648645\n",
      "         0.                 0.           3317474.66174916\n",
      "   7331681.48848664         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24453087.1592592          0.                 0.          48367057.44589729\n",
      "         0.                 0.           3317480.39549184\n",
      "   7331411.38084439         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24449397.66950564         0.                 0.          48370531.77906822\n",
      "         0.                 0.           3317485.22869946\n",
      "   7331183.69599856         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24446287.6467802          0.                 0.          48373460.43745706\n",
      "         0.                 0.           3317489.30280905\n",
      "   7330991.77107342         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24443666.08065623         0.                 0.          48375929.12411907\n",
      "         0.                 0.           3317492.73704366\n",
      "   7330829.98965685         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24441456.25470026         0.                 0.          48378010.081686\n",
      "         0.                 0.           3317495.63190132\n",
      "   7330693.61744397         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24439593.50147384         0.                 0.          48379764.20644474\n",
      "         0.                 0.           3317498.07209596\n",
      "   7330578.66369439         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24438023.31013223         0.                 0.          48381242.83038118\n",
      "         0.                 0.           3317500.12903643\n",
      "   7330481.76444886         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24436699.73124141         0.                 0.          48382489.22333843\n",
      "         0.                 0.           3317501.86291619\n",
      "   7330400.08408766         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24435584.03213279         0.                 0.          48383539.85924765\n",
      "         0.                 0.           3317503.32447478   7330331.2323503\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24434643.56344625         0.                 0.          48384425.48348628\n",
      "         0.                 0.           3317504.55648265\n",
      "   7330273.19438781         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24433850.80369271         0.                 0.          48385172.01259796\n",
      "         0.                 0.           3317505.59499279\n",
      "   7330224.27180113         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24433182.55387662         0.                 0.          48385801.29270377\n",
      "         0.                 0.           3317506.47039571   7330183.0329398\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24432619.25861003         0.                 0.          48386331.73879807\n",
      "         0.                 0.           3317507.20830885\n",
      "   7330148.27100671         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24432144.4338518          0.                 0.          48386778.87363733\n",
      "         0.                 0.           3317507.83032621\n",
      "   7330118.96874296         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24431744.18452539         0.                 0.          48387155.78199166\n",
      "         0.                 0.           3317508.35465023\n",
      "   7330094.26865914         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24431406.79789902         0.                 0.          48387473.49355227\n",
      "         0.                 0.           3317508.79662452\n",
      "   7330073.44794214         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24431122.40082915         0.                 0.          48387741.30569963\n",
      "         0.                 0.           3317509.16918283\n",
      "   7330055.89730307         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430882.67083681         0.                 0.          48387967.05557835\n",
      "         0.                 0.           3317509.48322757\n",
      "   7330041.10314725         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430680.59256205         0.                 0.          48388157.34944011\n",
      "         0.                 0.           3317509.74794879\n",
      "   7330028.63254456         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430510.2524693          0.                 0.          48388317.75596626\n",
      "         0.                 0.           3317509.97109321\n",
      "   7330018.12056042         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430366.66579609         0.                 0.          48388452.96922743\n",
      "         0.                 0.           3317510.15919082\n",
      "   7330009.25957645         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430245.63068106         0.                 0.          48388566.94604892\n",
      "         0.                 0.           3317510.31774603\n",
      "   7330001.79028846         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430143.60520234         0.                 0.          48388663.02180157\n",
      "         0.                 0.           3317510.45139875\n",
      "   7329995.49411828         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24430057.60372828         0.                 0.          48388744.00800672\n",
      "         0.                 0.           3317510.56406012\n",
      "   7329990.18681736         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429985.10954707         0.                 0.          48388812.27461138\n",
      "         0.                 0.           3317510.65902703\n",
      "   7329985.71307503         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429924.0012188          0.                 0.          48388869.81934146\n",
      "         0.                 0.           3317510.73907854\n",
      "   7329981.94197354         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429872.49049446         0.                 0.          48388918.32616223\n",
      "         0.                 0.           3317510.80655726\n",
      "   7329978.76315693         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429829.06998539         0.                 0.          48388959.21455737\n",
      "         0.                 0.           3317510.86343784\n",
      "   7329976.08360161         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429792.46905168         0.                 0.          48388993.68106808\n",
      "         0.                 0.           3317510.91138483\n",
      "   7329973.82489417         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429761.61661863         0.                 0.          48389022.73430815\n",
      "         0.                 0.           3317510.95180131\n",
      "   7329971.92093673         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429735.60983331         0.                 0.          48389047.22447969\n",
      "         0.                 0.           3317510.98587003\n",
      "   7329970.31601266         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429713.68764386         0.                 0.          48389067.86825297\n",
      "         0.                 0.           3317511.01458796\n",
      "   7329968.96315612         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429695.20852832         0.                 0.          48389085.26973891\n",
      "         0.                 0.           3317511.03879548\n",
      "   7329967.82277768         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429679.63172148         0.                 0.          48389099.93816742\n",
      "         0.                 0.           3317511.059201     7329966.86150577\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24429666.50139006         0.                 0.          48389112.30278939\n",
      "         0.                 0.           3317511.07640165\n",
      "   7329966.05121012         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429655.43329341         0.                 0.          48389122.725438\n",
      "         0.                 0.           3317511.09090079\n",
      "   7329965.36817858         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429646.10353934         0.                 0.          48389131.51111737\n",
      "         0.                 0.           3317511.1031227    7329964.79242319\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24429638.23910575         0.                 0.          48389138.91692804\n",
      "         0.                 0.           3317511.11342505\n",
      "   7329964.30709528         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429631.60985106         0.                 0.          48389145.15959057\n",
      "         0.                 0.           3317511.12210934\n",
      "   7329963.89799241         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429626.02177951         0.                 0.          48389150.42178769\n",
      "         0.                 0.           3317511.12942968\n",
      "   7329963.55314277         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429621.31136407         0.                 0.          48389154.85751015\n",
      "         0.                 0.           3317511.13560029\n",
      "   7329963.26245483         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429617.34076108         0.                 0.          48389158.59656315\n",
      "         0.                 0.           3317511.14080175\n",
      "   7329963.01742199         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429613.99377643         0.                 0.          48389161.74836476\n",
      "         0.                 0.           3317511.14518628\n",
      "   7329962.81087374         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429611.17246535         0.                 0.          48389164.40514803\n",
      "         0.                 0.           3317511.14888218\n",
      "   7329962.63676571         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429608.79426616         0.                 0.          48389166.64465996\n",
      "         0.                 0.           3317511.1519976    7329962.49000289\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24429606.78958421         0.                 0.          48389168.53243672\n",
      "         0.                 0.           3317511.15462372\n",
      "   7329962.36629047         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429605.0997553          0.                 0.          48389170.12372143\n",
      "         0.                 0.           3317511.15683739\n",
      "   7329962.26200818         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429603.67532898         0.                 0.          48389171.46508078\n",
      "         0.                 0.           3317511.15870338\n",
      "   7329962.17410436         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429602.47462144         0.                 0.          48389172.59576778\n",
      "         0.                 0.           3317511.1602763    7329962.10000659\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24429601.46249563         0.                 0.          48389173.54887038\n",
      "         0.                 0.           3317511.16160218\n",
      "   7329962.03754655         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[ 24429600.60933314         0.                 0.          48389174.35227978\n",
      "         0.                 0.           3317511.16271981   7329961.9848964\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n",
      "[ 24429600.60933314         0.                 0.          48389174.35227978\n",
      "         0.                 0.           3317511.16271981   7329961.9848964\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(normalized_all_train_feature_matrix, all_output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept =  24429600.6093\n",
      "bathrooms  =  0.0\n",
      "sqft_living  =  0.0\n",
      "sqft_lot  =  48389174.3523\n",
      "floors  =  0.0\n",
      "waterfront  =  0.0\n",
      "view  =  3317511.16272\n",
      "condition  =  7329961.9849\n",
      "grade  =  0.0\n",
      "sqft_above  =  0.0\n",
      "sqft_basement  =  0.0\n",
      "yr_built  =  0.0\n",
      "yr_renovated  =  0.0\n"
     ]
    }
   ],
   "source": [
    "print 'intercept = ', weights[0]\n",
    "for i in range(1,len(all_features)):\n",
    "    print all_features[i], ' = ', weights[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz:\n",
    "## for all features, l1_penalty=1e7, \n",
    "## the features have non-zero weight : sqft_lot, view, condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, learn the weights with `l1_penalty=1e4`, on the training data. Initialize weights to all zeros, and set the `tolerance=5e5`.  Call resulting weights `weights1e4`, you will need them later.  (This case will take quite a bit longer to converge than the others above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before while loop, max_change =  500000000.0\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 71114625.75280938   3956380.10169754   4963442.47090491\n",
      "   5351785.20244835  -1029778.70127717  -8770183.36166059\n",
      "  12531492.38446381  10818930.30035373  -8852214.38705103\n",
      "   3691006.48690016   6552708.56440671   2946362.53466733\n",
      " -11587978.82672676   3043479.31193253]\n",
      "[ 70458043.17373988   6425368.15103951   8547900.27630541   8914874.6783465\n",
      "  -1450214.98167019 -13686427.97272056   7599969.4022666   12239550.5873264\n",
      " -12644466.52258854   6608416.91505528  11849744.63068959\n",
      "   3426663.58888805 -20051994.77410842   3192423.86076874]\n",
      "[ 70403369.99725774   8029765.38655874  11725662.87650004\n",
      "  11908552.09885677  -1647027.40495416 -17274295.53307753   6637674.9450811\n",
      "  11699329.84283599 -15634070.12426525   8906988.10150192\n",
      "  16034491.41171806   3574599.33574975 -26870446.13280139\n",
      "   3106799.55239196]\n",
      "[ 70415249.40388955   8994652.98158435  14529291.14161976\n",
      "  14486684.75797745  -1743683.20857493 -19899995.01362915\n",
      "   6563586.29797617  10977693.54810274 -18097071.94550943\n",
      "  10686267.20056591  19285506.56035306   3667084.49006893\n",
      " -32440611.35181165   2987513.41029021]\n",
      "[ 70450964.48054764   9456361.77643505  16988899.66636615\n",
      "  16736762.56992277  -1801401.80189282 -21761923.06960092   6620246.8120482\n",
      "  10349514.34741229 -20100415.31766954  12031481.72752241\n",
      "  21767300.64645516   3748143.25893155 -37000449.81940535\n",
      "   2878937.97009907]\n",
      "[ 70499306.27673222   9519216.37605406  19138018.51724426\n",
      "  18728469.46937219  -1839465.55359354 -23021138.54666447   6680022.5254806\n",
      "   9833318.56865259 -21694979.67073987  13015705.67707694\n",
      "  23619694.01572518   3821930.65061695 -40732506.5165541    2787474.22568849]\n",
      "[ 70556926.98001137   9267912.40504879  21008659.30980168\n",
      "  20518129.49474231  -1864760.54478443 -23809863.85467513\n",
      "   6726819.64397519   9413131.9684151  -22928289.97291856\n",
      "  13701351.34916216  24959144.10579157   3886076.91681173\n",
      " -43785718.13007963   2711927.23115647]\n",
      "[ 70622246.76940551   8771897.12600913  22630212.57525808\n",
      "  22150908.65554322  -1880976.98751554 -24235174.3469699    6761132.54162502\n",
      "   9071818.27410585 -23844545.74228066  14141560.40378444\n",
      "  25882031.86355306   3937852.72751497 -46283235.56565493\n",
      "   2650093.04210199]\n",
      "[ 70694111.63321716   8088081.20032252  24029363.26834363\n",
      "  23662777.50995149  -1890718.29954909 -24383112.37816941\n",
      "   6785190.05348802   8794922.50933285 -24484268.60458405\n",
      "  14381463.13848996  26467862.19794324   3975271.71108588\n",
      " -48327104.53890122   2599900.8601471 ]\n",
      "[ 70771541.17942624   7262965.2415909   25230221.53548648\n",
      "  25082194.93920092  -1895973.69029975 -24322439.47710419   6800996.1521672\n",
      "   8570555.10887511 -24884240.02595019  14459293.42064055\n",
      "  26782048.13517928   3997172.76960736 -50001822.24795851\n",
      "   2559554.46760875]\n",
      "[ 70853678.24779327   6334401.6557595   26254500.38693175\n",
      "  26431512.25362653  -1898273.018061   -24107805.47881386\n",
      "   6810192.89013928   8388939.556973   -25077606.25583571\n",
      "  14407363.84376485  26878272.46271758   4003090.356523   -51377243.00488025\n",
      "   2527516.65654234]\n",
      "[ 70939771.75310194   5333068.90144943  27121703.32685478\n",
      "  27728134.06792218  -1898779.4760643  -23782375.40321065\n",
      "   6814121.53426841   8242031.63312234 -25094063.74775891\n",
      "  14252913.16601206  26800475.83336771   3993095.8709151  -52511001.04322623\n",
      "   2502475.66278923]\n",
      "[ 71029164.99152592   4283706.25027256  27849310.99552128\n",
      "  28985475.00402001  -1898362.68382362 -23379997.42321803\n",
      "   6813881.72798612   8123217.28195347 -24960083.21169407\n",
      "  14018840.07469758  26584524.78255634   3967654.91157036\n",
      " -53450542.58662399   2483313.64148042]\n",
      "[ 71121285.34786168   3206146.967868    28452961.9612801   30213746.25220951\n",
      "  -1897659.00976623 -22926988.66801348   6810376.00338104\n",
      "   8027067.58885802 -24699150.90278839  13724336.9913304   26259608.1036773\n",
      "   3927509.54520613 -54234832.34556033   2469079.20787987]\n",
      "[ 71215634.89820579   2116181.5819736   28946624.91806974\n",
      "  31420600.61692448  -1897121.13626887 -22443603.34456656\n",
      "   6804344.25175394   7949136.51157465 -24332014.82246416  13385436.5055181\n",
      "  25849403.64175337   3873584.81302296 -54895786.03774241\n",
      "   2458963.72051595]\n",
      "[ 71311781.85224953   1026278.01135321  29342760.65815508\n",
      "  32611660.02290411  -1897058.43405653 -21945236.89337689\n",
      "   6796391.51843984   7885792.5091182  -23876928.05055333\n",
      "  13015481.70772357  25373051.52104489   3806916.12920273\n",
      " -55459471.64364307   2452280.80910095]\n",
      "[  7.14093528e+07  -4.38187520e+04   2.96429300e+07   3.37906908e+07\n",
      "  -1.89763163e+06  -2.14433838e+07   6.78721475e+06   7.83424990e+06\n",
      "  -2.33505318e+07   1.26257841e+07   2.48461999e+07   3.72850163e+06\n",
      "  -5.59474412e+07   2.44852221e+06]\n",
      "[ 71507993.32793435  -1096810.61350567  29867403.3010437   34960468.22652747\n",
      "  -1898989.1201084  -20946466.81720556   6776935.10198      7791988.92702747\n",
      " -22766594.9611153   12225399.73166617  24281139.58567158\n",
      "   3639546.74602953 -56376884.63425812   2447112.57615299]\n",
      "[ 71607446.03297205  -2127010.69800525  30024904.32087586\n",
      "  36122808.90241341  -1901180.5201802  -20460515.27317084\n",
      "   6765921.61624515   7757017.44012918 -22137145.33910012\n",
      "  11821758.13987934  23687686.06191425   3541171.81580899\n",
      " -56761679.89577083   2447633.56908136]\n",
      "[ 71707476.45575935  -3130194.86727889  30123192.01053526\n",
      "  37278789.43142118  -1904207.673851   -19989672.37020741\n",
      "   6754453.00797374   7727754.55019864 -21472607.46944637\n",
      "  11420911.58590721  23073634.14840518   3434431.58705458\n",
      " -57112992.11137699   2449735.40807746]\n",
      "[ 71807883.68375167  -4103319.34369933  30169164.36499813  38428929.1110798\n",
      "  -1908040.69718753 -19536622.91188918   6742743.52085964\n",
      "   7702941.21793993 -20781972.26500382  11027750.08524469  22445136.5084435\n",
      "   3320318.68613732 -57439766.69594663   2453123.83675792]\n",
      "[ 71908496.69267987  -5044288.44894749  30168953.01986251\n",
      "  39573335.43859805  -1912627.42476488 -19102936.66013485\n",
      "   6730959.66105101   7681575.32964607 -20072957.66457634\n",
      "  10646185.39523179  21807016.39374477   3199760.50048469\n",
      " -57749134.53302304   2457551.52923475]\n",
      "[ 72009170.55143856  -5951763.78746076  30128008.54318151\n",
      "  40711819.35665143  -1917900.8245107  -18689342.16182944\n",
      "   6719230.92084649   7662861.83948121 -19352156.66199188\n",
      "  10279307.94041349  21163025.11242399   3073615.97042112\n",
      " -58046746.40090059   2462810.93349089]\n",
      "[ 72109783.02585495  -6825007.81399694  30051176.99663521\n",
      "  41843985.92834195  -1923784.886394   -18295944.20349889\n",
      "   6707657.36027255   7646173.09554801 -18625171.93767812\n",
      "   9929520.37553374  20516053.31449616   2942674.02292737\n",
      " -58337049.11007567   2468728.19536339]\n",
      "[ 72210231.57777053  -7663755.93285043  29942768.41378571\n",
      "  42969305.09612103  -1930199.1771156  -17922395.53736122   6696315.3634225\n",
      "   7631016.68485558 -17896737.32552228   9598651.06520737\n",
      "  19868303.86655198   2807653.78801217 -58623513.26230514\n",
      "   2475157.98640223]\n",
      "[ 72310430.72486711  -8468112.24387586  29806617.87108386  44087166.344997\n",
      "  -1937062.270082   -17568031.55609089   6685262.20370015\n",
      "   7617009.17288428 -17170826.78634568   9288050.34310628\n",
      "  19221432.87185844   2669206.29366251 -58908820.76424247\n",
      "   2481979.09901701]\n",
      "[ 72410309.72480908  -9238464.85221385  29646139.81854527\n",
      "  45196920.40781929  -1944294.25904624 -17231975.02516412\n",
      "   6674539.74367288   7603854.61420988 -16450751.73715353\n",
      "   8998672.03266939  18576664.33760457   2527917.25955139\n",
      " -59195018.86472008   2489090.69657604]\n",
      "[ 72509810.54871775  -9975417.33053197  29464376.31052481\n",
      "  46297910.58688641  -1951818.54116965 -16913216.70467713\n",
      "   6664177.46027324   7591326.98008155 -15739247.64810177\n",
      "   8731142.37324312  17934883.09177159   2384310.64533297\n",
      " -59483646.37770005   2496409.12382798]\n",
      "[ 72608886.11146477 -10679733.48748685  29264039.74139138\n",
      "  47389495.79932925  -1959563.02627197 -16610676.64109989\n",
      "   6654194.92457706   7579255.81858114 -15038550.82682289\n",
      "   8485818.19915671  17296709.79104003   2238852.67143904\n",
      " -59775836.83247112   2503865.19686616]\n",
      "[ 72707498.72909591 -11352293.07115438  29047550.65053215\n",
      "  48471067.06694315  -1967460.90110953 -16323250.03987653\n",
      "   6644603.83352102   7567514.58538889 -14350466.28809296\n",
      "   8262835.96095786  16662561.21951642   2091956.09167104 -60072402.5201377\n",
      "   2511401.90326693]\n",
      "[ 72805618.77654585 -11994056.43534169  28817071.1186029   49542058.85099637\n",
      "  -1975451.05307456 -16049840.91002429   6635409.67133347\n",
      "   7556011.17905178 -13676427.5681898    8062152.95373989\n",
      "  16032698.53845613   1943984.54992764 -60373902.75503322\n",
      "   2518972.45271993]\n",
      "[ 72903223.52153735 -12606036.53169867  28574534.23398763\n",
      "  50601956.36800331  -1983478.23712937 -15789386.07660438   6626613.0645135\n",
      "   7544680.29287884 -13017549.29459567   7883581.92316247\n",
      "  15407265.69422168   1795256.89694722 -60680699.12182868\n",
      "   2526538.62680303]\n",
      "[ 73000296.11311206 -13189276.87129993  28321670.06619973\n",
      "  51650299.80431405  -1991493.05277319 -15540871.66541565\n",
      "   6618210.88333995   7533477.26056072 -12374673.2673106    7726820.05171481\n",
      "  14786319.81217839   1646051.37780213 -60993000.01792765   2534069.3837628 ]\n",
      "[ 73096824.70559879 -13744834.33430015  28060028.54224626\n",
      "  52686686.16791669  -1999451.78390123 -15303343.75924986\n",
      "   6610197.13405242   7522373.12694213 -11748408.7509618    7591473.18267913\n",
      "  14169855.08672653   1496609.62836384 -61310896.41295968\n",
      "   2541539.68040054]\n",
      "[ 73192801.70097943 -14273765.90253694  27790999.58331861\n",
      "  53710769.36859237  -2007316.14306675 -15075914.59210304\n",
      "   6602563.67850634   7511350.72090002 -11139167.61924641\n",
      "   7477076.01417832  13557821.41250645   1347140.44036127\n",
      " -61634390.42156369   2548929.478563  ]\n",
      "[ 73288223.09456968 -14777118.55365186  27515830.82290232\n",
      "  54722258.99706232  -2015052.952461   -14857765.37474035\n",
      "   6595300.81196111   7500401.54542258 -10547194.93654715\n",
      "   7383108.88803237  12950138.78074577   1197823.27112155\n",
      " -61963418.01262708   2556222.90840373]\n",
      "[ 73383087.91070156 -15255921.69159218  27235643.1937012   55720918.1754542\n",
      "  -2022633.78650825 -14648146.62179718   6588397.72450814\n",
      "   7489523.33191072  -9972595.50687647   7309011.70561152\n",
      "  12346708.28074053   1048811.48657816 -62297866.94957239\n",
      "   2563407.56460817]\n",
      "[ 73477397.71668267 -15711181.60162     26951444.63972183\n",
      "  56706560.77147163  -2030034.59501785 -14446376.66864272\n",
      "   6581842.86732317   7478718.1324117   -9415356.86835432\n",
      "   7254195.42344638  11747420.39364027    900235.33545501\n",
      " -62637590.86523269   2570473.9152479 ]\n",
      "[ 73571156.20473263 -16143877.51190473  26664142.1814538   57679048.20387435\n",
      "  -2037235.3210786  -14251838.91840223   6575624.24130455\n",
      "   7467990.84576806  -8875369.16266314   7218051.51327335  11152161.1390115\n",
      "    752204.65934119 -62982420.21543457   2577414.80591684]\n",
      "[ 73664368.83286579 -16554958.92154345  26374552.53624396\n",
      "  58638286.01460132  -2044219.52410384 -14063978.23986861\n",
      "   6569729.62262649   7457348.09222278  -8352442.26360708   7199959.7129157\n",
      "  10560816.52983624    604811.3481955  -63332170.72261179\n",
      "   2584225.04437095]\n",
      "[ 73757042.51682007 -16945343.9190936   26083411.47258899\n",
      "  59584220.34086725  -2050974.01545583 -13882296.84055665   6564146.7372012\n",
      "   7446797.36645616  -7846320.50713592   7199294.3445817    9973275.70507338\n",
      "    458131.55409456 -63686649.81035419   2590901.05309673]\n",
      "[ 73849185.36613184 -17315918.26864491  25791382.05602475\n",
      "  60516834.38698481  -2057488.511746   -13706349.86172273\n",
      "   6558863.39392883   7436346.41184209  -7356695.32696997   7215429.4346285\n",
      "   9389433.03764457    312227.67811533 -64045661.43816216\n",
      "   2597440.57912324]\n",
      "[ 73940806.45834252 -17667535.08398625  25499061.9254197   61436144.96897266\n",
      "  -2063755.30909857 -13535740.88034145   6553867.58485168   7426002.7693254\n",
      "  -6883216.06519475   7247742.83257819   8809189.45715783\n",
      "    167150.14640229 -64409009.66978171   2603842.4520096 ]\n",
      "[  7.40319156e+07  -1.80010149e+07   2.52069897e+07   6.23421992e+07\n",
      "  -2.06976898e+06  -1.33701175e+07   6.54914756e+06   7.41577346e+06\n",
      "  -6.42549920e+06   7.29561950e+06   8.23245318e+06   2.29389919e+04\n",
      "  -6.47765012e+07   2.61010638e+06]\n",
      "[ 74122523.39262748 -18317146.35656348  24915650.77540829  63235071.2396262\n",
      "  -2075526.09552364 -13209166.80547764   6544691.87441142\n",
      "   7405664.79248273  -5983136.17031681   7358454.08396987\n",
      "   7659139.98989246   -110374.74150683 -65153424.07543665\n",
      "   2615630.67589748]\n",
      "[ 74212745.7639222  -18617354.98720227  24625310.89272813\n",
      "  64114180.54186894  -2080623.03938879 -13050643.25639899\n",
      "   6539829.62417301   7393705.33220502  -5555841.01593176\n",
      "   7435735.21389072   7089598.40885846   -249076.06865601 -65530894.8448007\n",
      "   2621648.06166946]\n",
      "[ 74302363.05652425 -18901869.18957838  24336470.90538798\n",
      "  64980218.80861064  -2085589.65565366 -12895864.52383382   6536373.161289\n",
      "   7382690.72804019  -5143421.28800944   7526752.3030583    6523424.16029724\n",
      "   -388829.46520248 -65910878.6359024    2627489.15088229]\n",
      "[ 74391525.42230538 -19171254.38632731  24049440.1774434   65833410.25804015\n",
      "  -2090409.10990521 -12744985.40987977   6533002.49768361\n",
      "   7372479.98725948  -4745037.21640523   7630912.54194357\n",
      "   5960469.12518533   -528318.3054093  -66293869.74784499\n",
      "   2633188.96611091]\n",
      "[ 74480238.30673446 -19426136.32962465  23764534.05617966\n",
      "  66673932.03905246  -2095033.49425069 -12597933.79657926\n",
      "   6529650.15635451   7362718.8213967   -4360080.46894521\n",
      "   7747671.65637144   5400663.80861817   -667113.81947533\n",
      " -66679939.66085462   2638765.67528125]\n",
      "[ 74568509.7170359  -19667137.1211308   23482049.9739771   67501960.44301473\n",
      "  -2099435.52954723 -12454581.13903787   6526408.66093967\n",
      "   7353223.05262395  -3988064.72059052   7876510.03157465\n",
      "   4843963.58038866   -805069.2941659  -67069027.3522013    2644221.2618321 ]\n",
      "[ 74656350.77676028 -19894860.91920403  23202257.95921475\n",
      "  68317678.36383352  -2103605.07742011 -12314788.07383987\n",
      "   6523329.36642881   7343916.66289271  -3628549.82757878\n",
      "   8016924.95293102   4290332.49054386   -942133.51141467\n",
      " -67461028.62442157   2649556.0087401 ]\n",
      "[ 74743772.98492688 -20109890.71371153  22925399.54018817\n",
      "  69121276.57021192  -2107540.79069869 -12178419.66254727\n",
      "   6520429.18703839   7334769.87668855  -3281112.73002093   8168428.3067665\n",
      "   3739738.25443628  -1078289.75322336 -67855825.65193075\n",
      "   2654770.97804204]\n",
      "[ 74830787.72998872 -20312787.79349066  22651689.13189986  69912953.3399049\n",
      "  -2111245.24563622 -12045350.25627893   6517709.57601346\n",
      "   7325770.39042661  -2945338.24169251   8330546.06811189\n",
      "   3192150.66568285  -1213534.90721968 -68253297.33755827\n",
      "   2659867.88205567]\n",
      "[ 74917406.28334747 -20504091.98687953  22381316.00938137\n",
      "  70692913.56275889  -2114722.75997823 -11915464.46152626\n",
      "   6515166.16303774   7316912.12887554  -2620816.96584328\n",
      "   8502818.30534662   2647541.07467869  -1347871.9988659  -68653323.13647737\n",
      "   2664848.80104334]\n",
      "[ 75003639.81461033 -20684322.16637712  22114446.31937694\n",
      "  71461367.70213431  -2117978.49434991 -11788656.69686903\n",
      "   6512792.62287543   7308191.11910478  -2307145.53398507\n",
      "   8684799.27422957   2105882.18439801  -1481307.35771914\n",
      " -69055784.54672267   2669716.02246067]\n",
      "[ 75089499.38431072 -20853976.85632775  21851224.97699123\n",
      "  72218530.76129451  -2121018.07709346 -11664830.29769249\n",
      "   6510582.10689959   7299604.01723613  -2003927.47702859\n",
      "   8876057.46814334   1567147.92609812  -1613849.42165727\n",
      " -69460565.71959689   2674471.95840308]\n",
      "[ 75174995.92585117 -21013534.88298357  21591777.41182812\n",
      "  72964621.30759691  -2123847.43032275 -11543896.52479172\n",
      "   6508527.75415343   7291147.59367117  -1710774.15915818\n",
      "   9076175.59225549   1031313.34443917  -1745508.13928742\n",
      " -69867553.71122715   2679119.09921613]\n",
      "[ 75260140.22554404 -21163456.03990937  21336211.16423779\n",
      "  73699860.57140899  -2126472.67336433 -11425773.60449411\n",
      "   6506622.86888363   7282818.56180737  -1427305.5976612    9284750.46235662\n",
      "    498354.47588148  -1876294.60515991 -70276638.57122847\n",
      "   2683659.98354334]\n",
      "[  7.53449429e+07  -2.13041818e+07   2.10846173e+07   7.44244716e+07\n",
      "  -2.12890006e+06  -1.13103858e+07   6.50486098e+06   7.27461353e+06\n",
      "  -1.15315113e+06   9.50139284e+06  -2.17517791e+04  -2.01105327e+06\n",
      "  -7.06941681e+07   2.68827413e+06]\n",
      "[ 75429411.30791576 -21436342.97698668  20836700.89231296\n",
      "  75138474.53324303  -2131480.07109075 -11197917.39279994\n",
      "   6503344.93164291   7267258.73950084   -886863.29366967\n",
      "   9725175.46887965   -540426.17084753  -2140714.64374941\n",
      " -71114320.98133761   2692498.46302133]\n",
      "[ 75513634.48468992 -21560513.36627846  20592554.99724714\n",
      "  75841867.53558549  -2133760.53722388 -11087618.03372092\n",
      "   6501447.31199506   7259422.85188969   -628269.61481589\n",
      "   9955940.56481081  -1057250.00438623  -2268204.18512725\n",
      " -71535830.74545708   2696677.17660405]\n",
      "[ 75597547.886314   -21677046.61355089  20352314.91557647\n",
      "  76534905.83488953  -2135764.76338327 -10979367.19552954\n",
      "   6499838.28453614   7251336.08311599   -377416.80551807\n",
      "  10193453.16591396  -1572010.75900919  -2394432.44606011\n",
      " -71958368.69165784   2700785.54760896]\n",
      "[ 75681163.63263842 -21786246.73877129  20116068.12640893\n",
      "  77217866.42409582  -2137542.19447457 -10873170.5563233    6498490.1230788\n",
      "   7243248.78284126   -134167.24073146  10437452.54795087\n",
      "  -2084576.01203042  -2519707.58462796 -72381861.88597679\n",
      "   2704814.06306584]\n",
      "[ 75764491.62824951 -21888405.86078615  19883875.72180129\n",
      "  77891021.55939512  -2139125.08317686 -10769059.71098118   6497316.7572788\n",
      "   7235270.71251612     91702.43935162  10697340.89965372\n",
      "  -2595200.11729962  -2643771.49972039 -72805946.73833807\n",
      "   2708628.71144236]\n",
      "[ 75847585.96069363 -21983944.33738023  19655499.7479356   78554535.15998912\n",
      "  -2140500.36443442 -10666987.43207754   6496227.13420276\n",
      "   7227291.62511829    311257.85793419  10962602.76455069\n",
      "  -3103696.40635849  -2766935.83491139 -73230631.45669554\n",
      "   2712390.41585379]\n",
      "[ 75930419.80184774 -22073103.97058238  19431024.1537464   79208683.84135062\n",
      "  -2141700.65438589 -10567003.73520386   6495303.0616439    7219422.86331841\n",
      "    524604.76360781  11233042.68867881  -3609935.10469792\n",
      "  -2889330.23365991 -73655959.55169059   2716088.64403777]\n",
      "[ 76013001.33782342 -22156127.97878236  19210508.07775977\n",
      "  79853729.28740239  -2142745.07569664 -10469147.63408834\n",
      "   6494499.52938092   7211702.88040815    731905.28048693\n",
      "  11508457.28924977  -4113820.24229886  -3011005.87832181\n",
      " -74081978.90748534   2719721.84155615]\n",
      "[ 76095337.26883696 -22233261.26595003  18993994.34271784\n",
      "  80489921.16621514  -2143645.82443206 -10373443.50241128\n",
      "   6493793.13763292   7204134.00783068    933339.09583683\n",
      "  11788639.86548847  -4615280.21105351  -3131986.58929823\n",
      " -74508723.87943563   2723289.64857872]\n",
      "[ 76177434.24353349 -22304748.84703746  18781512.08513323\n",
      "  81117498.39598772  -2144411.635851   -10279900.94189081\n",
      "   6493173.62986269   7196706.53251972   1129091.77152762  12073382.9132784\n",
      "  -5114262.32972978  -3252286.41251874 -74936211.91101554\n",
      "   2726791.87180917]\n",
      "[ 76259298.99182412 -22370834.1684023   18573078.36061363\n",
      "  81736690.36290801  -2145049.58385187 -10188516.60493547\n",
      "   6492635.81786232   7189407.99249122   1319350.29358086  12362479.7598741\n",
      "  -5610729.0801292   -3371915.78488671 -75364444.70568326\n",
      "   2730228.52966835]\n",
      "[ 76340938.26474699 -22431757.64944784  18368699.41178192\n",
      "  82347718.01992661  -2145565.86884735 -10099276.51965338\n",
      "   6492176.24722065   7182226.28976446   1504301.07566579\n",
      "  12655725.75179617  -6104655.23354807  -3490883.75199017\n",
      " -75793410.57496199   2733599.88929707]\n",
      "[ 76422358.78728786 -22487755.49384615  18168371.76993006\n",
      "  82950794.81605719  -2145966.15479275 -10012158.30006653   6491792.0033935\n",
      "   7175150.5696775    1684128.86098226  12952919.16860638\n",
      "  -6596025.55365908  -3609198.79064613 -76223086.86927004\n",
      "   2736906.45421082]\n",
      "[ 76503567.22818044 -22539058.75221028  17972083.24610845\n",
      "  83546127.45663106  -2146255.7247571   -9927133.05044309\n",
      "   6491480.31442069   7168171.34357451   1859015.9882788   13253861.94049876\n",
      "  -7084832.92343187  -3726869.12730686 -76653442.16382006\n",
      "   2740148.93324174]\n",
      "[ 76584570.17870483 -22585892.6024581   17779813.83372751\n",
      "  84133916.51490505  -2146439.56337874  -9844166.94030872\n",
      "   6491238.43331119   7161280.37675517   2029141.83399951\n",
      "  13558360.21196067  -7571076.80598702  -3843902.86769936\n",
      " -77084438.12923364   2743328.20629068]\n",
      "[ 76665374.13640727 -22628475.81322153  17591536.53373503  84714356.9196263\n",
      "  -2146522.4075159   -9763222.48187078   6491063.61480033\n",
      "   7154470.52047127   2194682.36200132  13866224.77921844  -8054761.976839\n",
      "  -3960308.05126887 -77516031.09957151   2746445.29237964]\n",
      "[ 76745985.49201693 -22667020.35904685  17407218.10960538\n",
      "  85287638.34163457  -2146508.78102829  -9684259.55463285   6490953.1217256\n",
      "   7147735.54637923   2355809.75359795  14177271.42232355  -8535897.4796113\n",
      "  -4076092.67268059 -77948173.37372485   2749501.32150905]\n",
      "[ 76826410.51877902 -22701731.16043618  17226819.77794063\n",
      "  85853945.49945182  -2146403.02027269  -9607236.22076529\n",
      "   6490904.23885814   7141070.00026177   2512692.10493331  14491321.1487941\n",
      "  -9014495.76664538  -4191264.6871137  -78380814.28929593\n",
      "   2752497.51043276]\n",
      "[ 76906655.36378203 -22732805.9259211   17050297.83983898\n",
      "  86413458.40054406  -2146209.29340626  -9532109.36947596\n",
      "   6490914.28690769   7134469.07782754   2665493.18360222\n",
      "  14808200.36300469  -9490571.99275603  -4305832.00671047\n",
      " -78813901.10499795   2755435.14202632]\n",
      "[ 76986726.04099558 -22760435.07702909  16877604.25779439\n",
      "  86966352.53199013  -2145931.61521329  -9458835.22266703   6490980.6345628\n",
      "   7127928.5209828    2814372.23818799  15127740.97339765\n",
      "  -9964143.43577953  -4419802.4919158  -79247379.72294849\n",
      "   2758315.54781859]\n",
      "[ 77066628.42579724 -22784801.74015903  16708687.18257258\n",
      "  87512799.01176386  -2145573.85856724  -9387369.728673     6491100.70816523\n",
      "   7121444.531841     2959483.85510591  15449780.44783238\n",
      " -10435229.02197643  -4533183.9398954  -79681195.27757844\n",
      "   2761140.09326295]\n",
      "[ 77146368.25080033 -22806081.79206005  16543491.4342096   88052964.70971417\n",
      "  -2145139.76332716  -9317668.8661267    6491271.99917145\n",
      "   7115013.70169538   3100977.85755181  15774161.82589524\n",
      " -10903848.93802218  -4645984.07145899 -80115292.613695     2763910.16536367]\n",
      "[ 77225951.10281791 -22824443.94786642  16381958.94098557\n",
      "  88587012.34556444  -2144632.94327624  -9249688.87599677   6491492.0697005\n",
      "   7108632.9524639    3238999.24169157  16100733.69570858\n",
      " -11370024.31438799  -4758210.51747349 -80549616.67261732\n",
      "   2766627.16231942]\n",
      "[ 77305382.420816   -22840049.88254014  16224029.13993886\n",
      "  89115100.56979686  -2144056.89157609  -9183386.43650493\n",
      "   6491758.55647912   7102299.48846796   3373688.14555891\n",
      "  16429350.14166929 -11833776.96748446  -4869870.80545826 -80984112.8022193\n",
      "   2769292.48489027]\n",
      "[ 77384667.494726   -22853054.37816522  16069639.34220595\n",
      "  89637384.03209038  -2143414.98510857  -9118718.79286839\n",
      "   6492069.17346518   7096010.75674138   3505179.84646802\n",
      "  16759870.66859279 -12295129.19009213  -4980972.34684454\n",
      " -81418727.00410537   2771907.5292349 ]\n",
      "[ 77463811.46500006 -22863605.49087038  15918725.06620476\n",
      "  90154013.44099891  -2142710.48799702  -9055643.85153354\n",
      "   6492421.71339145   7089764.41436184   3633604.78309203\n",
      "  17092160.10691383 -12754103.58140294  -5091522.42522349\n",
      " -81853406.12894711   2774473.68099984]\n",
      "[ 77542819.32280602 -22871844.73227042  15771220.34142497\n",
      "  90665135.61775577  -2141946.55453484  -8994120.2466927    6492814.04843412\n",
      "   7083558.30154976   3759088.59869994  17426088.50288767\n",
      " -13210722.90949967  -5201528.18578806 -82288098.02916056\n",
      "   2776992.31047348]\n",
      "[ 77621695.91077125 -22877907.26124704  15627057.98535054\n",
      "  91170893.54643793  -2141126.23169792  -8934107.38533814\n",
      "   6493244.13017707   7077390.41949347   3881752.20237834\n",
      "  17761530.99712483 -13665010.00035385  -5310996.6260834  -82722751.67655382\n",
      "   2779464.76864428]\n",
      "[ 77700445.92419413 -22881922.08266103  15486169.8558169   91671426.42219624\n",
      "  -2140252.46137636  -8875565.47585072   6493709.989014     7071258.91203887\n",
      "   4001711.84538301  18098367.69427003 -14116987.64846645\n",
      "  -5419934.58811257 -83157317.25127509   2781892.38402544]\n",
      "[ 77779073.91265212 -22884012.25023353  15348487.08089995\n",
      "  92166869.69883077  -2139328.0824278   -8818455.54409492\n",
      "   6494209.73310655   7065162.05053198   4119079.21006765\n",
      "  18436483.52618775 -14566678.54514347  -5528348.75179428 -83591746.2073053\n",
      "   2784276.46012858]\n",
      "intercept =  24429600.6093\n",
      "bathrooms  =  -22884012.2502\n",
      "sqft_living  =  15348487.0809\n",
      "sqft_lot  =  92166869.6988\n",
      "floors  =  -2139328.08243\n",
      "waterfront  =  -8818455.54409\n",
      "view  =  6494209.73311\n",
      "condition  =  7065162.05053\n",
      "grade  =  4119079.21007\n",
      "sqft_above  =  18436483.5262\n",
      "sqft_basement  =  -14566678.5451\n",
      "yr_built  =  -5528348.75179\n",
      "yr_renovated  =  -83591746.2073\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.zeros(len(all_features)+1)\n",
    "l1_penalty = 1e4\n",
    "tolerance = 5e5\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_all_train_feature_matrix, all_output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print 'intercept = ', weights[0]\n",
    "for i in range(1,len(all_features)):\n",
    "    print all_features[i], ' = ', weights1e4[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz:\n",
    "## for all features, l1_penalty=1e4, tolerance=5e5,\n",
    "## all features have non-zero weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we normalized our feature matrix, before learning the weights.  To use these weights on a test set, we must normalize the test data in the same way.\n",
    "\n",
    "Alternatively, we can rescale the learned weights to include the normalization, so we never have to worry about normalizing the test data: \n",
    "\n",
    "In this case, we must scale the resulting weights so that we can make predictions with *original* features:\n",
    " 1. Store the norms of the original features to a vector called `norms`:\n",
    "```\n",
    "features, norms = normalize_features(features)\n",
    "```\n",
    " 2. Run Lasso on the normalized features and obtain a `weights` vector\n",
    " 3. Compute the weights for the original features by performing element-wise division, i.e.\n",
    "```\n",
    "weights_normalized = weights / norms\n",
    "```\n",
    "Now, we can apply `weights_normalized` to the test data, without normalizing it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of each of the weights learned above. (`weights1e4`, `weights1e7`, `weights1e8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your results, if you call `normalized_weights1e7` the normalized version of `weights1e7`, then:\n",
    "```\n",
    "print normalized_weights1e7[3]\n",
    "```\n",
    "should return 161.31745624837794."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating each of the learned models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the three models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, all_features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS of each of the three normalized weights on the (unnormalized) `test_feature_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Which model performed best on the test data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
